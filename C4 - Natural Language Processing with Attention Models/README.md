## Week 3 Ungraded Labs

[Question Answering with HuggingFace 1](https://drive.google.com/file/d/1O4LvdhHw6Zx7Kd43HK-p5a1rtsHUEia5/view?usp=sharinghttps://drive.google.com/file/d/1O4LvdhHw6Zx7Kd43HK-p5a1rtsHUEia5/view?usp=sharing)

[Question Answering with HuggingFace 2](https://drive.google.com/file/d/1P8COnbYLphJNaW3v8wS1AwpahnV-653A/view?usp=sharing)

## Week 3 Ungraded Assignments

[BERT Loss Model Colab](https://drive.google.com/file/d/1Hz15z7TGxx-5MYizMfCGD5CcRt2ZDbL5/view?usp=sharing)

[T5 SQuAD Model Colab](https://drive.google.com/file/d/1hc7PaXjuuMS0likb0etEHY0ryAzsqAZR/view?usp=sharing)

## References

[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) (Raffel et al, 2019)

[Reformer: The Efficient Transformer](https://arxiv.org/abs/2001.04451) (Kitaev et al, 2020)

[Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Vaswani et al, 2017)

[Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf) (Peters et al, 2018)

[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer) (Alammar, 2018)

[The Illustrated GPT-2 (Visualizing Transformer Language Models)](http://jalammar.github.io/illustrated-gpt2) (Alammar, 2019)

[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805) (Devlin et al, 2018)

[How GPT3 Works - Visualizations and Animations](http://jalammar.github.io/how-gpt3-works-visualizations-animations) (Alammar, 2020)

[Jukebox - A neural network that generates music!](https://openai.com/blog/jukebox/)

[GPT-3 Can also help with auto-programming!](https://beta.openai.com/?app=productivity&example=4_2_0)
